model: transformer
learning_rate: 1e-4
lr_policy: multistep
lr_decay_milestones: [50,100]
dins: "69,85"
douts: "69"
input_modalities: "expmap_scaled_20,audio_feats_scaled_20"
output_modalities: "expmap_scaled_20"
input_lengths: "120,140"
output_lengths: "3"
output_time_offsets: "120"
nlayers: 12
optimizer: adam
nhead: 10
dhid: 800
dropout: 0
use_pos_emb_output: True
batch_size: 64
gradient_clip_val: 0.5
