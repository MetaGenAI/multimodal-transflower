model: transformer
learning_rate: 1e-4
lr_policy: multistep
lr_decay_milestones: [50,100]
dins: "69,85"
douts: "69"
input_modalities: "expmap_scaled_20,audio_feats_scaled_20"
output_modalities: "expmap_scaled_20"
input_lengths: "120,140"
output_lengths: "3"
output_time_offsets: "120"
nlayers: 16
optimizer: adam
nhead: 10
dhid: 1600
dropout: 0
#use_pos_emb_output: True
#batch_size: 128
gradient_clip_val: 0.5
#sync_batchnorm: True
