model: transformer
learning_rate: 1e-4
lr_policy: multistep
lr_decay_milestones: [50,100]
#lr_policy: LinearWarmupCosineAnnealing
dins: 67,85
douts: 67
input_modalities: "expmap_cr_scaled_60,audio_feats_scaled_60"
output_modalities: expmap_cr_scaled_60
#input_types: d,c,c
#input_num_tokens: 16,0,0
input_lengths: "120,240"
output_lengths: "10"
output_time_offsets: "120"
nlayers: 12
optimizer: adam
nhead: 10
dhid: 800
dropout: 0
#use_pos_emb_output: True
batch_size: 32
gradient_clip_val: 0.5
#precision: 16
#plugins: deepspeed
