model: moglow
lr_policy: "multistep"
lr_decay_milestones: "[100,200]"
learning_rate: 1e-3
dins: 31
douts: 31
input_modalities: "person1_scaled"
output_modalities: person1_scaled
input_lengths: "119"
input_seq_lens: "60"
output_lengths: "60"
output_time_offsets: "60"
flow_dist: studentT
glow_K: 24
dhid: 128
dropout: 0.1
gradient_clip_val: 10
batch_size: 100
network_model: transformer
#batch_size: 8
