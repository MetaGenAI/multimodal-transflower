model: moglow
lr_policy: "multistep"
lr_decay_milestones: "[100,200]"
learning_rate: 1e-3
dins: 3,31
douts: 3,31
input_modalities: "root_pos_scaled,proc_feats"
output_modalities: root_pos_scaled,proc_feats
input_lengths: "119,119"
input_seq_lens: "60,60"
output_lengths: "60,60"
output_seq_lens: "1,1"
output_time_offsets: "60,60"
flow_dist: studentT
glow_K: 24
dhid: 128
dropout: 0.1
gradient_clip_val: 10
batch_size: 100
network_model: transformer
#batch_size: 8
