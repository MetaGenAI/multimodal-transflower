model: transformer
learning_rate: 3e-5
dins: "219,103"
douts: "219"
input_modalities: "joint_angles_scaled,mel_ddcpca_scaled"
output_modalities: "joint_angles_scaled"
input_lengths: "120,240"
output_lengths: "20"
output_time_offset: "121"
predicted_inputs: "0,0"
nlayers: 12
optimizer: adam
nhead: 10
dhid: 800
dropout: 0
use_pos_emb_output: True
gpus: 1
batch_size: 8
gradient_clip_val: 0.5
