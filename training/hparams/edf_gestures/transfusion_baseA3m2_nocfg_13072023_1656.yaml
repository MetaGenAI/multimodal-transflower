model: transfusion
dins: 1,21
douts: 21
input_modalities: "speech.wav_envelope_scaled,motion_features_scaled1"
output_modalities: motion_features_scaled1
input_lengths: 121,120
output_lengths: 1
output_time_offsets: 120
input_dropouts: 0,0
cond_dropout_probs: "0.0"
num_diff_steps: 100
num_sampling_steps: 100
nhead: 8
nlayers: 18
diffu_depth: 3
diffu_num_heads: 8
diffu_model_mean_type: START_X
diffu_model_var_type: FIXED_SMALL
#diffu_model_var_type: FIXED_LARGE
#diffu_model_var_type: LEARNED_RANGE
dhid: 800
dhid_diffu: 800 #need to allow for this to be diff from dhid
diffu_patch_size: (1,3)
diffu_scale_betas: 20
#diffu_patch_size: (1,1)
use_rel_pos_emb_inputs: True
use_pos_emb_output: True
#use_pos_emb_output: True
#cond_concat_dims: True
conditioning_seq_lens: 5
diffu_concat_conds: True
dropout: 0
#lr_policy: cosine
#lr_policy: plateau
lr_policy: multistep
#lr_policy: plateau
#lr_policy: step
lr_decay_milestones: "[4000,8000,16000,32000,64000,128000]"
#lr_decay_iters: 1
lr_decay_factor: 0.5
scheduler_interval: step
#lr_scheduler_frequency: 1000
#lr_plateau_patience: 2
#lr_plateau_threshold: 0.01
#lr_policy: LinearWarmupCosineAnnealing
optimizer: adamw
#optimizer: adam
#optimizer: rmsprop
learning_rate: 5e-5
#learning_rate: 1e-2
gradient_clip_val: 0
batch_size: 32
#batch_size: 128
#batch_size: 28

